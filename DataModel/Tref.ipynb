{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read data from ASCII files\n",
    "folder_path = \"/Users/soumilhooda/Desktop/WD/Data-WD/Weather/ALL-VALID\"\n",
    "data = {}\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.startswith(\"rainnn\") or file_name.startswith(\"maxtmp\") or file_name.startswith(\"mintmp\"):\n",
    "        year = file_name[-10:-6]\n",
    "        data_type = file_name[:6]\n",
    "        df = pd.read_csv(os.path.join(folder_path, file_name), delim_whitespace=True, header=None)\n",
    "        num_days = df.shape[1] - 2  # Deducting 2 for Latitude and Longitude columns\n",
    "        date_range = pd.date_range(start=f'{year}-01-01', periods=num_days)\n",
    "        date_columns = date_range.strftime('%Y-%m-%d').tolist()\n",
    "        df.columns = ['Latitude', 'Longitude'] + date_columns\n",
    "        data[(data_type, year)] = df\n",
    "        \n",
    "# Step 2: Calculate average temperature\n",
    "for year in range(1951, 2024):\n",
    "    maxtmp = data[('maxtmp', str(year))]\n",
    "    mintmp = data[('mintmp', str(year))]\n",
    "    avg_tmp = (maxtmp.iloc[:, 2:] + mintmp.iloc[:, 2:]) / 2\n",
    "    data[('avgtmp', str(year))] = pd.concat([maxtmp.iloc[:, :2], avg_tmp], axis=1)\n",
    "\n",
    "\n",
    "# Step 3: Create dictionary with (latitude, longitude) pairs and rainfall/temperature data\n",
    "result = {}\n",
    "\n",
    "for year in range(1951, 2024):\n",
    "    for lat, lon in zip(data[('rainnn', str(year))]['Latitude'], data[('rainnn', str(year))]['Longitude']):\n",
    "        if (lat, lon) not in result:\n",
    "            result[(lat, lon)] = pd.DataFrame(columns=['Rainfall', 'Temperature'])\n",
    "        rain = data[('rainnn', str(year))][(data[('rainnn', str(year))]['Latitude'] == lat) & (data[('rainnn', str(year))]['Longitude'] == lon)].iloc[:, 2:].values.flatten()\n",
    "        temp = data[('avgtmp', str(year))][(data[('avgtmp', str(year))]['Latitude'] == lat) & (data[('avgtmp', str(year))]['Longitude'] == lon)].iloc[:, 2:].values.flatten()\n",
    "        date_index = pd.date_range(start=f'{year}-01-01', end=f'{year}-12-31')\n",
    "        df = pd.DataFrame({'Rainfall': rain, 'Temperature': temp}, index=pd.DatetimeIndex(date_index))\n",
    "        result[(lat, lon)] = pd.concat([result[(lat, lon)], df])\n",
    "\n",
    "# Filter the result dictionary to keep only key-value pairs with 26663 rows\n",
    "filtered_result = {key: value for key, value in result.items() if len(value) == 26663}\n",
    "\n",
    "# Load GeoLocations.csv\n",
    "geo_df = pd.read_csv(\"/Users/soumilhooda/Desktop/WD/Data-WD/GeoLocations/GeoLocations.csv\")\n",
    "\n",
    "data = {}\n",
    "\n",
    "for key, df in filtered_result.items():\n",
    "    lat, lon = key\n",
    "    state_df = geo_df[(geo_df['Latitude'] == lat) & (geo_df['Longitude'] == lon)]\n",
    "    if not state_df.empty:\n",
    "        state_name = state_df['State Name'].iloc[0]\n",
    "        # Check if the state name is not 'MAHARASHTRA'\n",
    "        if state_name != 'MAHARASHTRA':\n",
    "            new_key = (lat, lon, state_name)\n",
    "            data[new_key] = df\n",
    "        else:\n",
    "            print(f\"Latitude {lat} and longitude {lon} corresponds to the state of Maharashtra, skipping...\")\n",
    "    else:\n",
    "        print(f\"No state found for latitude {lat} and longitude {lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "temperature = {\n",
    "    'Date': pd.date_range(start='2018-01-01', end='2023-12-31'),\n",
    "}\n",
    "\n",
    "# Create DataFrame from dictionary\n",
    "temperature = pd.DataFrame(temperature) \n",
    "\n",
    "\n",
    "def mean_and_variance(filtered_result, start_date=None, end_date=None):\n",
    "    # Create an empty dictionary to store aggregated data for each state\n",
    "    state_data = {}\n",
    "\n",
    "    # Iterate through keys and aggregate data by state\n",
    "    for key, df in filtered_result.items():\n",
    "        lat, lon, state_name = key\n",
    "        # Apply start and end date filters\n",
    "        if start_date and end_date:\n",
    "            df = df.loc[start_date:end_date]\n",
    "        # Initialize state data if not already present\n",
    "        if state_name not in state_data:\n",
    "            state_data[state_name] = {'Temperature': [], 'Rainfall': [], 'Count': 0}\n",
    "        # Append data to state data\n",
    "        state_data[state_name]['Temperature'].append(df['Temperature'])\n",
    "        state_data[state_name]['Rainfall'].append(df['Rainfall'])\n",
    "        state_data[state_name]['Count'] += 1\n",
    "\n",
    "    # Calculate mean temperature for each state\n",
    "    for i, (state, data) in enumerate(state_data.items()):\n",
    "        mean_temp = np.mean(data['Temperature'],axis=0)\n",
    "        temperature[state] = mean_temp\n",
    "\n",
    "# Example usage with custom start and end dates\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-12-31'\n",
    "mean_and_variance(data, start_date, end_date)\n",
    "\n",
    "electricity = pd.read_csv('/Users/soumilhooda/Desktop/WD/Data-WD/Electricity/Electricity.csv')\n",
    "electricity[\"Date\"] = pd.to_datetime(electricity[\"Date\"])\n",
    "electricity.set_index(\"Date\", inplace=True)\n",
    "temperature[\"Date\"] = pd.to_datetime(temperature[\"Date\"])\n",
    "temperature.set_index(\"Date\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "electricity = electricity.sort_index()\n",
    "temperature = temperature.sort_index()\n",
    "\n",
    "states = ['PUNJAB', 'GUJARAT', 'HARYANA', 'HIMACHAL PRADESH', 'MADHYA PRADESH', 'BIHAR', 'UTTAR PRADESH', 'KARNATAKA', 'TELANGANA', 'ANDHRA PRADESH', 'RAJASTHAN', 'ORISSA']\n",
    "\n",
    "def find_tref_peak_correlation_HDD(state, electricity_data, temperature_data):\n",
    "    \"\"\"Finds Tref based on the temperature at maximum correlation\"\"\"\n",
    "\n",
    "    # Calculate rolling correlations with a weekly window\n",
    "    correlations = electricity_data.rolling(window='90D').corr(temperature_data)\n",
    "\n",
    "    # Find base temperatures\n",
    "    tref_hdd = temperature_data.loc[correlations.idxmin()]\n",
    "\n",
    "    return tref_hdd\n",
    "\n",
    "def find_tref_peak_correlation_CDD(state, electricity_data, temperature_data):\n",
    "    \"\"\"Finds Tref based on the temperature at maximum correlation\"\"\"\n",
    "\n",
    "    # Calculate rolling correlations with a weekly window\n",
    "    correlations = electricity_data.rolling(window='90D').corr(temperature_data)\n",
    "\n",
    "    # Find base temperatures\n",
    "    tref_cdd = temperature_data.loc[correlations.idxmax()]  # Temperature at strongest positive corr\n",
    "\n",
    "    return tref_cdd\n",
    "\n",
    "# Calculate Trefs\n",
    "trefs = {}\n",
    "for state in states:\n",
    "    electricity[state] = electricity[state].replace('-', np.nan).astype(float)\n",
    "    electricity[state] = electricity[state].interpolate(method='linear')\n",
    "\n",
    "    trefs[f\"{state}_HDD\"] = find_tref_peak_correlation_HDD(state, electricity[state], temperature[state])\n",
    "    trefs[f\"{state}_CDD\"] = find_tref_peak_correlation_CDD(state, electricity[state], temperature[state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ... (Load your data, ensure indexes are sorted) ...\n",
    "\n",
    "states = ['PUNJAB', 'GUJARAT', 'HARYANA', 'HIMACHAL PRADESH', 'MADHYA PRADESH', 'BIHAR', 'UTTAR PRADESH', 'KARNATAKA', 'TELANGANA', 'ANDHRA PRADESH', 'RAJASTHAN', 'ORISSA']\n",
    "WINTER_MONTHS = [1, 2, 10, 11, 12]\n",
    "MONSOON_MONTHS = [3, 4, 5, 6, 7, 8, 9]\n",
    "TEMP_RANGE = 2  # 2 degrees Celsius range\n",
    "\n",
    "def find_tref_peak_correlation_HDD(state, electricity_data, temperature_data):\n",
    "    # Filter data for winter months\n",
    "    winter_data = electricity_data[electricity_data.index.month.isin(WINTER_MONTHS)]\n",
    "    winter_temp = temperature_data[temperature_data.index.month.isin(WINTER_MONTHS)]\n",
    "\n",
    "    correlations = winter_data.rolling(window='90D').corr(winter_temp)\n",
    "    avg_temp_neg_corr = temperature_data.loc[correlations.idxmin()].mean()\n",
    "\n",
    "    # Find base temp within +- TEMP_RANGE of avg_temp_neg_corr\n",
    "    temp_lower = avg_temp_neg_corr - TEMP_RANGE\n",
    "    temp_upper = avg_temp_neg_corr + TEMP_RANGE\n",
    "    tref_hdd = temperature_data[(temperature_data >= temp_lower) & (temperature_data <= temp_upper)].mean()\n",
    "\n",
    "    return tref_hdd\n",
    "\n",
    "def find_tref_peak_correlation_CDD(state, electricity_data, temperature_data):\n",
    "    # Filter data for monsoon months\n",
    "    monsoon_data = electricity_data[electricity_data.index.month.isin(MONSOON_MONTHS)]\n",
    "    monsoon_temp = temperature_data[temperature_data.index.month.isin(MONSOON_MONTHS)]\n",
    "\n",
    "    correlations = monsoon_data.rolling(window='90D').corr(monsoon_temp)\n",
    "    avg_temp_pos_corr = temperature_data.loc[correlations.idxmax()].mean()\n",
    "\n",
    "    # Find base temp within +- TEMP_RANGE of avg_temp_pos_corr\n",
    "    temp_lower = avg_temp_pos_corr - TEMP_RANGE\n",
    "    temp_upper = avg_temp_pos_corr + TEMP_RANGE\n",
    "    tref_cdd = temperature_data[(temperature_data >= temp_lower) & (temperature_data <= temp_upper)].mean()\n",
    "\n",
    "    return tref_cdd\n",
    "\n",
    "# Calculate Trefs\n",
    "trefs = {}\n",
    "for state in states:\n",
    "    electricity[state] = electricity[state].replace('-', np.nan).astype(float)\n",
    "    electricity[state] = electricity[state].interpolate(method='linear')\n",
    "\n",
    "    trefs[f\"{state}_HDD\"] = find_tref_peak_correlation_HDD(state, electricity[state], temperature[state])\n",
    "    trefs[f\"{state}_CDD\"] = find_tref_peak_correlation_CDD(state, electricity[state], temperature[state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "states = ['PUNJAB', 'GUJARAT', 'HARYANA', 'HIMACHAL PRADESH', 'MADHYA PRADESH', 'BIHAR', 'UTTAR PRADESH', 'KARNATAKA', 'TELANGANA', 'ANDHRA PRADESH', 'RAJASTHAN', 'ORISSA']\n",
    "WINTER_MONTHS = [1, 2, 10, 11, 12]\n",
    "MONSOON_MONTHS = [3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "def find_tref_peak_correlation_HDD(state, electricity_data, temperature_data):\n",
    "    # Filter data for winter months\n",
    "    winter_data = electricity_data[electricity_data.index.month.isin(WINTER_MONTHS)]\n",
    "    winter_temp = temperature_data[temperature_data.index.month.isin(WINTER_MONTHS)]\n",
    "\n",
    "    # Sort the DataFrame by index\n",
    "    winter_data = winter_data.sort_index()\n",
    "    winter_temp = winter_temp.sort_index()\n",
    "\n",
    "    correlations = winter_data.rolling(window='90D').corr(winter_temp)\n",
    "    avg_temp_neg_corr = temperature_data.loc[correlations.idxmin()].mean()\n",
    "    std_dev = temperature_data.loc[correlations.idxmin()].std()  # Calculate standard deviation\n",
    "\n",
    "    # Find base temp within +- 1 standard deviation\n",
    "    temp_lower = avg_temp_neg_corr \n",
    "    temp_upper = avg_temp_neg_corr + std_dev\n",
    "    tref_hdd = temperature_data[(temperature_data >= temp_lower) & (temperature_data <= temp_upper)].mean()\n",
    "\n",
    "    return tref_hdd\n",
    "\n",
    "def find_tref_peak_correlation_CDD(state, electricity_data, temperature_data):\n",
    "    # Filter data for monsoon months\n",
    "    monsoon_data = electricity_data[electricity_data.index.month.isin(MONSOON_MONTHS)]\n",
    "    monsoon_temp = temperature_data[temperature_data.index.month.isin(MONSOON_MONTHS)]\n",
    "\n",
    "    # Sort the DataFrame by index\n",
    "    monsoon_data = monsoon_data.sort_index()\n",
    "    monsoon_temp = monsoon_temp.sort_index()\n",
    "\n",
    "    correlations = monsoon_data.rolling(window='90D').corr(monsoon_temp)\n",
    "    avg_temp_pos_corr = temperature_data.loc[correlations.idxmax()].mean()\n",
    "    std_dev = temperature_data.loc[correlations.idxmax()].std()  # Calculate standard deviation\n",
    "\n",
    "    # Find base temp within +- 1 standard deviation\n",
    "    temp_lower = avg_temp_pos_corr - std_dev\n",
    "    temp_upper = avg_temp_pos_corr \n",
    "    tref_cdd = temperature_data[(temperature_data >= temp_lower) & (temperature_data <= temp_upper)].mean()\n",
    "\n",
    "    return tref_cdd\n",
    "\n",
    "# Calculate Trefs\n",
    "trefs = {}\n",
    "for state in states:\n",
    "    electricity[state] = electricity[state].replace('-', np.nan).astype(float)\n",
    "    electricity[state] = electricity[state].interpolate(method='linear')\n",
    "\n",
    "    trefs[f\"{state}_HDD\"] = find_tref_peak_correlation_HDD(state, electricity[state], temperature[state])\n",
    "    trefs[f\"{state}_CDD\"] = find_tref_peak_correlation_CDD(state, electricity[state], temperature[state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trefs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
